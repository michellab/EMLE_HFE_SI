{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import warnings\n",
    "from typing import Union\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import torch\n",
    "from emle.models import EMLE\n",
    "from emle.train._utils import pad_to_max\n",
    "\n",
    "KJ_PER_MOL_TO_KCAL_PER_MOL = 1.0 / 4.184\n",
    "HARTEE_TO_KJ_MOL = 2625.5\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_statistic(\n",
    "    y_true: np.ndarray,\n",
    "    y_pred: np.ndarray,\n",
    "    dy_true: Union[np.ndarray, None] = None,\n",
    "    dy_pred: Union[np.ndarray, None] = None,\n",
    "    ci: float = 0.95,\n",
    "    statistic: str = \"RMSE\",\n",
    "    nbootstrap: int = 500,\n",
    "    include_true_uncertainty: bool = False,\n",
    "    include_pred_uncertainty: bool = False,\n",
    ") -> dict:\n",
    "    def compute_statistic(y_true_sample, y_pred_sample, statistic):\n",
    "        if statistic == \"RMSE\":\n",
    "            return np.sqrt(\n",
    "                sklearn.metrics.mean_squared_error(y_true_sample, y_pred_sample)\n",
    "            )\n",
    "        elif statistic == \"MUE\":\n",
    "            return sklearn.metrics.mean_absolute_error(y_true_sample, y_pred_sample)\n",
    "        elif statistic == \"MSE\":\n",
    "            return np.mean(y_pred_sample - y_true_sample)\n",
    "        elif statistic == \"R2\":\n",
    "            slope, intercept, r_value, _, _ = scipy.stats.linregress(\n",
    "                y_true_sample, y_pred_sample\n",
    "            )\n",
    "            return r_value**2\n",
    "        elif statistic == \"rho\":\n",
    "            return scipy.stats.pearsonr(y_true_sample, y_pred_sample)[0]\n",
    "        elif statistic == \"KTAU\":\n",
    "            return scipy.stats.kendalltau(y_true_sample, y_pred_sample)[0]\n",
    "        else:\n",
    "            raise Exception(f\"unknown statistic '{statistic}'\")\n",
    "\n",
    "    if dy_true is None:\n",
    "        dy_true = np.zeros_like(y_true)\n",
    "    if dy_pred is None:\n",
    "        dy_pred = np.zeros_like(y_pred)\n",
    "\n",
    "    N = len(y_true)\n",
    "    s_n = np.zeros([nbootstrap], np.float64)\n",
    "    for replicate in range(nbootstrap):\n",
    "        idx = np.random.choice(np.arange(N), size=N, replace=True)\n",
    "        y_true_sample = y_true[idx] + np.random.normal(\n",
    "            0, dy_true[idx] if include_true_uncertainty else 0\n",
    "        )\n",
    "        y_pred_sample = y_pred[idx] + np.random.normal(\n",
    "            0, dy_pred[idx] if include_pred_uncertainty else 0\n",
    "        )\n",
    "        s_n[replicate] = compute_statistic(y_true_sample, y_pred_sample, statistic)\n",
    "\n",
    "    s_n_sorted = np.sort(s_n)\n",
    "    low_frac = (1.0 - ci) / 2.0\n",
    "    high_frac = 1 - low_frac\n",
    "\n",
    "    return {\n",
    "        \"mle\": compute_statistic(y_true, y_pred, statistic),\n",
    "        \"mean\": np.mean(s_n),\n",
    "        \"stderr\": np.std(s_n),\n",
    "        \"low\": s_n_sorted[int(np.floor(nbootstrap * low_frac))],\n",
    "        \"high\": s_n_sorted[int(np.ceil(nbootstrap * high_frac))],\n",
    "    }\n",
    "\n",
    "\n",
    "def calculate_rmse(predicted, reference):\n",
    "    return np.sqrt(np.mean((predicted - reference) ** 2))\n",
    "\n",
    "\n",
    "source_path = \"../../../\"\n",
    "models_dict = {\n",
    "    \"General Model\": source_path + \"emle_models/emle_qm7_aev.mat\",\n",
    "    \"Bespoke Model\": source_path + \"emle_models/ligand_bespoke_iter2.mat\",\n",
    "    \"Patched Model\": source_path + \"emle_models/ligand_patched_species_iter2.mat\",\n",
    "}\n",
    "\n",
    "testing_data_paths = [\n",
    "    source_path + \"data/testing_datasets/testing_data_iter1.pkl\",\n",
    "    source_path + \"data/testing_datasets/testing_data_iter2.pkl\",\n",
    "    source_path + \"data/testing_datasets/testing_data_iter3.pkl\",\n",
    "]\n",
    "\n",
    "xyz_qm, xyz_mm, z, charges_mm = [], [], [], []\n",
    "e_static_ref, e_ind_ref = [], []\n",
    "\n",
    "s, q_core, q_val, alpha = [], [], [], []\n",
    "\n",
    "for path in testing_data_paths:\n",
    "    data = pkl.load(open(path, \"rb\"))\n",
    "    xyz_qm += data[\"xyz_qm\"]\n",
    "    xyz_mm += data[\"xyz_mm\"]\n",
    "    z += data[\"z\"]\n",
    "    charges_mm += data[\"charges_mm\"]\n",
    "    e_static_ref += data[\"e_static\"]\n",
    "    e_ind_ref += data[\"e_ind\"]\n",
    "\n",
    "    # For MBIS/atomic properties\n",
    "    s += data.get(\"s\", [])\n",
    "    q_core += data.get(\"q_core\", [])\n",
    "    q_val += data.get(\"q_val\", [])\n",
    "    alpha += data.get(\"alpha\", [])\n",
    "\n",
    "# Pad and convert to tensors\n",
    "xyz_qm = pad_to_max(xyz_qm)\n",
    "xyz_mm = pad_to_max(xyz_mm)\n",
    "z = pad_to_max(z)\n",
    "charges_mm = pad_to_max(charges_mm)\n",
    "e_static_ref = torch.tensor(e_static_ref)\n",
    "e_ind_ref = torch.tensor(e_ind_ref)\n",
    "\n",
    "s_ref = pad_to_max(s)\n",
    "q_core_ref = pad_to_max(q_core)\n",
    "q_val_ref = pad_to_max(q_val)\n",
    "alpha_ref = pad_to_max(alpha)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "emle_energy_dict = {}\n",
    "emle_mbis_dict = {}\n",
    "\n",
    "for model_name, model_path in models_dict.items():\n",
    "    emle_model = EMLE(model=model_path, alpha_mode=\"species\", device=device).double()\n",
    "    e_static_emle, e_ind_emle = emle_model.forward(z, charges_mm, xyz_qm, xyz_mm)\n",
    "    e_static_emle = e_static_emle.detach().cpu().numpy()\n",
    "    e_ind_emle = e_ind_emle.detach().cpu().numpy()\n",
    "    emle_energy_dict[model_name] = {\n",
    "        \"e_static_emle\": e_static_emle * HARTEE_TO_KJ_MOL,\n",
    "        \"e_ind_emle\": e_ind_emle * HARTEE_TO_KJ_MOL,\n",
    "    }\n",
    "\n",
    "    # MBIS/atomic properties\n",
    "    emle_base = emle_model._emle_base\n",
    "    s_emle, q_core_emle, q_val_emle, A_thole_emle = emle_base.forward(\n",
    "        z, xyz_qm, torch.zeros(len(xyz_qm))\n",
    "    )\n",
    "    mask = z > 0\n",
    "    n_atoms = mask.shape[1]\n",
    "    mask_mat = (\n",
    "        (mask[:, :, None] * mask[:, None, :])\n",
    "        .repeat_interleave(3, dim=1)\n",
    "        .repeat_interleave(3, dim=2)\n",
    "    )\n",
    "    A_thole_inv = torch.where(mask_mat, torch.linalg.inv(A_thole_emle), 0.0)\n",
    "    alpha_emle = (\n",
    "        torch.sum(A_thole_inv.reshape((-1, n_atoms, 3, n_atoms, 3)), dim=(1, 3))\n",
    "        .detach()\n",
    "        .numpy()\n",
    "    )\n",
    "\n",
    "    emle_mbis_dict[model_name] = {\n",
    "        \"s\": s_emle.detach().numpy(),\n",
    "        \"q_core\": q_core_emle.detach().numpy(),\n",
    "        \"q_val\": q_val_emle.detach().numpy(),\n",
    "        \"alpha\": alpha_emle,\n",
    "        \"z\": z.detach().numpy(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = (e_static_ref.numpy() + e_ind_ref.numpy()) * KJ_PER_MOL_TO_KCAL_PER_MOL\n",
    "predicted = {\n",
    "    name: (d[\"e_static_emle\"] + d[\"e_ind_emle\"]) * KJ_PER_MOL_TO_KCAL_PER_MOL\n",
    "    for name, d in emle_energy_dict.items()\n",
    "}\n",
    "\n",
    "data = []\n",
    "rmse_values = {}\n",
    "\n",
    "s_ref_flat = s_ref.detach().numpy().flatten()\n",
    "q_ref_flat = (q_val_ref.detach().numpy() + q_core_ref.detach().numpy()).flatten()\n",
    "alpha_ref_flat = alpha_ref.detach().numpy().flatten()\n",
    "\n",
    "for model_name, mbis in emle_mbis_dict.items():\n",
    "    s_pred = mbis[\"s\"].flatten()\n",
    "    q_pred = mbis[\"q_val\"].flatten() + mbis[\"q_core\"].flatten()\n",
    "    alpha_pred = mbis[\"alpha\"].flatten()\n",
    "\n",
    "    rmse_values[model_name] = {\n",
    "        \"S\": calculate_rmse(s_pred, s_ref_flat),\n",
    "        \"Charge\": calculate_rmse(q_pred, q_ref_flat),\n",
    "        \"Polarizability\": calculate_rmse(alpha_pred, alpha_ref_flat),\n",
    "    }\n",
    "\n",
    "    for type_, ref, pred, key in [\n",
    "        (\"S vs Sref\", s_ref_flat, s_pred, \"S\"),\n",
    "        (\"Charges\", q_ref_flat, q_pred, \"Charge\"),\n",
    "        (\"Polarizability\", alpha_ref_flat, alpha_pred, \"Polarizability\"),\n",
    "    ]:\n",
    "        data.extend(\n",
    "            [\n",
    "                {\"Model\": model_name, \"Atom\": \"All\", \"Difference\": v, \"Type\": type_}\n",
    "                for v in (pred - ref)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = (e_static_ref.numpy() + e_ind_ref.numpy()) * KJ_PER_MOL_TO_KCAL_PER_MOL\n",
    "predicted = {\n",
    "    name: (d[\"e_static_emle\"] + d[\"e_ind_emle\"]) * KJ_PER_MOL_TO_KCAL_PER_MOL\n",
    "    for name, d in emle_energy_dict.items()\n",
    "}\n",
    "\n",
    "s_ref_flat = s_ref.detach().numpy().flatten()\n",
    "q_ref_flat = (q_val_ref.detach().numpy() + q_core_ref.detach().numpy()).flatten()\n",
    "alpha_ref_flat = alpha_ref.detach().numpy().flatten()\n",
    "z_flat = z.detach().numpy().flatten()  # atomic numbers\n",
    "\n",
    "atomic_masks = {\n",
    "    \"H\": (z_flat == 1),\n",
    "    \"C\": (z_flat == 6),\n",
    "    \"N\": (z_flat == 7),\n",
    "    \"O\": (z_flat == 8),\n",
    "    \"S\": (z_flat == 16),\n",
    "}\n",
    "\n",
    "data = []\n",
    "rmse_values = {}\n",
    "\n",
    "for model_name, mbis in emle_mbis_dict.items():\n",
    "    s_pred = mbis[\"s\"].flatten()\n",
    "    q_pred = mbis[\"q_val\"].flatten() + mbis[\"q_core\"].flatten()\n",
    "    alpha_pred = mbis[\"alpha\"].flatten()\n",
    "\n",
    "    rmse_values[model_name] = {\n",
    "        \"S\": calculate_rmse(s_pred, s_ref_flat),\n",
    "        \"Charge\": calculate_rmse(q_pred, q_ref_flat),\n",
    "        \"Polarizability\": calculate_rmse(alpha_pred, alpha_ref_flat),\n",
    "    }\n",
    "\n",
    "    for type_, ref, pred, key in [\n",
    "        (\"S vs Sref\", s_ref_flat, s_pred, \"S\"),\n",
    "        (\"Charges\", q_ref_flat, q_pred, \"Charge\"),\n",
    "    ]:\n",
    "        for atom, mask in atomic_masks.items():\n",
    "            mask = mask[: len(ref)]  # ensure shapes match\n",
    "            diffs = (pred - ref)[mask]\n",
    "            data.extend(\n",
    "                [\n",
    "                    {\"Model\": model_name, \"Atom\": atom, \"Difference\": d, \"Type\": type_}\n",
    "                    for d in diffs\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    diffs = alpha_pred - alpha_ref_flat\n",
    "    data.extend(\n",
    "        [\n",
    "            {\"Model\": model_name, \"Atom\": \"\", \"Difference\": d, \"Type\": \"Polarizability\"}\n",
    "            for d in diffs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", palette=\"colorblind\", context=\"paper\", font_scale=1.5)\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "gs = gridspec.GridSpec(2, 3, height_ratios=[1, 0.7])\n",
    "\n",
    "x = np.linspace(-75, 10, 100)\n",
    "y = x\n",
    "for i, (model_name, pred_vals) in enumerate(predicted.items()):\n",
    "    ax = fig.add_subplot(gs[0, i])\n",
    "    ax.scatter(reference, pred_vals, alpha=0.7, label=model_name)\n",
    "    ax.plot(x, y, \"k--\", label=\"Reference\")\n",
    "    ax.set_xlabel(\"$E^{QM/MM}_{int}$ [kcal.mol$^{-1}$]\")\n",
    "    ax.set_ylabel(\"$E^{EMLE}_{int}$ [kcal.mol$^{-1}$]\")\n",
    "    ax.set_xlim(-75, 10)\n",
    "    ax.set_ylim(-75, 10)\n",
    "    ax.set_aspect(\"equal\")\n",
    "\n",
    "    metrics = [\"R2\", \"RMSE\", \"MUE\", \"MSE\", \"rho\", \"KTAU\"]\n",
    "    statistics = {}\n",
    "    statistics_string = \"\"\n",
    "    statistic_type = \"mle\"\n",
    "    statistic_name = {\n",
    "        \"RMSE\": r\"RMSE\",\n",
    "        \"MUE\": r\"MUE\",\n",
    "        \"MSE\": r\"MSE\",\n",
    "        \"R2\": r\"R$^2$\",\n",
    "        \"rho\": r\"$\\rho$\",\n",
    "        \"KTAU\": r\"$\\tau$\",\n",
    "    }\n",
    "\n",
    "    for statistic in metrics:\n",
    "        statistics[statistic] = bootstrap_statistic(\n",
    "            reference, pred_vals, statistic=statistic\n",
    "        )\n",
    "        s = statistics[statistic]\n",
    "        string = (\n",
    "            f\"{statistic_name[statistic]}: {s[statistic_type]:.2f} [{s['low']:.2f}, {s['high']:.2f}]\"\n",
    "            + \"\\n\"\n",
    "        )\n",
    "        statistics_string += string\n",
    "\n",
    "    ax.text(\n",
    "        0.02,\n",
    "        0.98,\n",
    "        f\"{model_name}\\n{statistics_string}\",\n",
    "        transform=ax.transAxes,\n",
    "        ha=\"left\",\n",
    "        va=\"top\",\n",
    "    )\n",
    "\n",
    "plot_configs = [\n",
    "    (\"S vs Sref\", \"Valence widths ($s$)\", \"$s^{EMLE}-s^{MBIS}$ [$a_0$]\", \"S\"),\n",
    "    (\"Charges\", \"Charges (QEq)\", r\"$q^{EMLE}-q^{MBIS}$ [$e$]\", \"Charge\"),\n",
    "    (\n",
    "        \"Polarizability\",\n",
    "        r\"Molecular polarizability ($\\alpha$)\",\n",
    "        r\"$\\alpha^{EMLE}_{mol}-\\alpha^{B3LYP}_{mol}$ [$a_0^3$]\",\n",
    "        \"Polarizability\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "for i, (type_, title, ylabel, rmse_key) in enumerate(plot_configs):\n",
    "    ax = fig.add_subplot(gs[1, i])\n",
    "    sns.violinplot(\n",
    "        x=\"Atom\",\n",
    "        y=\"Difference\",\n",
    "        hue=\"Model\",\n",
    "        data=df[df[\"Type\"] == type_],\n",
    "        ax=ax,\n",
    "        split=False,\n",
    "        inner=\"quart\",\n",
    "        palette=\"colorblind\",\n",
    "    )\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlabel(\"\")\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    new_labels = [f\"{label} ({rmse_values[label][rmse_key]:.2e})\" for label in labels]\n",
    "    ax.legend(handles=handles, labels=new_labels, loc=\"upper center\")\n",
    "\n",
    "\n",
    "axes = fig.get_axes()\n",
    "labels = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]\n",
    "for ax, label in zip(axes, labels):\n",
    "    ax.text(\n",
    "        -0.1,\n",
    "        1.05,\n",
    "        label,\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=32,\n",
    "        fontweight=\"bold\",\n",
    "        va=\"bottom\",\n",
    "        ha=\"right\",\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.00)\n",
    "plt.savefig(\"fig3_emle_vs_qmmm.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emle-sire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
